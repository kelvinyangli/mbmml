# library(bnlearn)
# library(gtools)
dag = randDag(8, 2)
# graphviz.plot(dag)
cpts = randCPTs(dag, 2, 1)
n = 100
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
# data_cat = numeric2categorical(data)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
# data_num = data.matrix(data_cat)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
forward_greedy(data, arities, vars, n, "V1", "cpt")
forward_greedy(data, arities, vars, n, "V1", "cpt", debug = T)
forward_greedy(data, arities, vars, n, "V1", "nb", debug = T)
# library(mbmml)
# library(bnlearn)
# library(gtools)
dag = randDag(8, 2)
# graphviz.plot(dag)
cpts = randCPTs(dag, 2, 1)
library(mbmml)
library(bnlearn)
library(gtools)
dag = randDag(8, 2)
# graphviz.plot(dag)
cpts = randCPTs(dag, 2, 1)
dag = randDag(8, 2)
cpts = randCPTs(dag, 2, 1)
n = 100
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
forward_greedy(data, arities, vars, n, "V1", "cpt", debug = T)
vars
sampleSize=n
n
target
target="V1"
model="cpt"
sigma=3
targetIndex = which(vars == target) # get index of the target node
targetIndex
nvars = length(vars)
nvars
mb = c()
unCheckedIndices = (1:nvars)[-targetIndex]
alpha
alpha=1
if (prod(alpha == 1)) alpha = rep(1, arities[targetIndex])
?mml_cpt
forward_greedy(data, arities, vars, n, "V1", "cpt", varCnt = di, debug = T)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
forward_greedy_fast(data, di, arities, vars, n, "V2", debug = T)
forward_greedy_fast(data, di, arities, vars, n, "V3", debug = T)
forward_greedy(data, arities, vars, n, "V3", "cpt", varCnt = di, debug = T)
forward_greedy(data, arities, vars, n, "V1", "nb", varCnt = di, debug = T)
model
model="nb"
# 1. initializing a probs matrix for furture use
# 2. caching p(x|T) for each x in the list cachedPXGivenT to avoid redundent computations
# 3. calculating log(p(T)) for the empty model
probsMtx = matrix(0.5, arities[targetIndex], sampleSize)
probsMtx
cachedPXGivenT = list() # empty list to cach condProbsAdpt calculated by mml_fixed_str_adaptive()
for (i in 1:nvars) {
if (i == targetIndex) {
cachedPXGivenT[[i]] = probs_adaptive(data, arities, sampleSize, probsMtx, targetIndex)
} else {
cachedPXGivenT[[i]] = cond_probs_adaptive(data, arities, sampleSize, targetIndex, probsMtx, i, targetIndex)
}
}
i
i
target
i
i=1
probs_adaptive(data, arities, sampleSize, probsMtx, targetIndex)
i
i=2
cond_probs_adaptive(data, arities, sampleSize, targetIndex, probsMtx, i, targetIndex)
probsMtx
curIndex
curIndex=i
curPaIndices
curPaIndices=targetIndex
ind = which(c(curPaIndices, curIndex) == targetIndex)
cnt = rep(1, arities[curIndex]) # initializing cnt with 1
for (i in rev(curPaIndices)) {
# make cnt a high-dim list to store variable count
# each lvl in the list corresponds to one value of one pa
# e.g. if two binary parents, then cnt is a list with 4 lvls
# the rev(curPaIndices) ensures the 1st pa's 1st value is in the
# most inner lvl
cnt = rep(list(cnt), arities[i])
}
cnt
# initializing prob matrix with 0.5, since the first probs are always 0.5 due to
# initial count being set to 1
# each row of probs corresponds to a value of the target var
# this probs matrix will be used later to obtain the normalizing constant when
# calculating the condtional probability p(T|Xs)
for (i in 1:(sampleSize - 1)) {# counting adaptively at each data point
indices = data[i, c(curPaIndices, curIndex)]
cnt[[matrix(indices, 1)]] = cnt[[matrix(indices, 1)]] + 1 # updating cnt
indices = data[i + 1, c(curPaIndices, curIndex)] # computing prob from 2nd data point
for (k in 1:arities[targetIndex]) {# loop through each value of the target
indices[ind] = k
probsMtx[k, i + 1] = cnt[[matrix(indices, 1)]] / sum(cnt[[matrix(indices[-length(indices)], 1)]])
}
} # end adaptive counting
i
indices = data[i, c(curPaIndices, curIndex)]
indices
cnt[[matrix(indices, 1)]] = cnt[[matrix(indices, 1)]] + 1 # updating cnt
cnt
# make cnt a high-dim list to store variable count
# each lvl in the list corresponds to one value of one pa
# e.g. if two binary parents, then cnt is a list with 4 lvls
# the rev(curPaIndices) ensures the 1st pa's 1st value is in the
# most inner lvl
cnt = rep(list(cnt), arities[i])
cnt
ind = which(c(curPaIndices, curIndex) == targetIndex)
cnt = rep(1, arities[curIndex]) # initializing cnt with 1
for (i in rev(curPaIndices)) {
# make cnt a high-dim list to store variable count
# each lvl in the list corresponds to one value of one pa
# e.g. if two binary parents, then cnt is a list with 4 lvls
# the rev(curPaIndices) ensures the 1st pa's 1st value is in the
# most inner lvl
cnt = rep(list(cnt), arities[i])
}
i=1
indices = data[i, c(curPaIndices, curIndex)]
cnt[[matrix(indices, 1)]] = cnt[[matrix(indices, 1)]] + 1 # updating cnt
indices
matrix(indices, 1)
data
forward_greedy(data, arities, vars, n, "V1", "cpt", varCnt = di, debug = T)
forward_greedy(data_num, arities, vars, n, "V1", "nb", varCnt = di, debug = T)
data_num = factor2numeric(data)
forward_greedy(data_num, arities, vars, n, "V1", "nb", varCnt = di, debug = T)
forward_greedy(data_num, arities, vars, n, "V1", "nb", debug = T)
forward_greedy(data_num, arities, vars, n, "V1", "nb", debug = T)
dag = randDag(8, 2)
cpts = randCPTs(dag, 2, 1)
n = 100
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
data_num = factor2numeric(data)
head(data)
head(data_num)
head(data.matrix(data))
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
data_num = data.matrix(data)
forward_greedy(data, arities, vars, n, "V1", "cpt", varCnt = di, debug = T)
forward_greedy(data_num, arities, vars, n, "V1", "nb", debug = T)
forward_greedy(data_num, arities, vars, n, "V1", "random", varCnt = varCnt, prior = "uniform")
dag = randDag(8, 3)
graphviz.plot(dag)
dag = randDag(8, 3)
graphviz.plot(dag)
dag = randDag(8, 2)
graphviz.plot(dag)
cpts = randCPTs(dag, 2, 1)
n = 20
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
data_num = data.matrix(data)
forward_greedy(data, arities, vars, n, "V1", "cpt", varCnt = di, debug = T)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = T)
n = 100
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
data_num = data.matrix(data)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = T)
forward_greedy(data_num, arities, vars, n, "V4", "nb", debug = T)
forward_greedy(data_num, arities, vars, n, "V4", "random", varCnt = varCnt, prior = "uniform", debug=T)
n = 500
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
data_num = data.matrix(data)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = T)
forward_greedy(data_num, arities, vars, n, "V4", "nb", debug = T)
forward_greedy(data_num, arities, vars, n, "V4", "random", varCnt = varCnt, prior = "uniform", debug=T)
library(ggplot2)
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.7, 0.05),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
p9
y <- dnorm(x, mean = 0.2, sd = 0.1)
y <- dnorm(0.5, mean = 0.2, sd = 0.1)
y
y[x < 0.2 | x > (0.2 + 4 * 0.1)]
x
x=0.5
x < 0.2 | x > (0.2 + 4 * 0.1)
y[x < 0.2 | x > (0.2 + 4 * 0.1)]
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 4 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.2)
p9
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 1 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.2)
p9
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 0.5 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.2)
p9
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.7, 0.05),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 0.5 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.2)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.7, 0.05),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.2)
p9
?stat_function
source('~/.active-rstudio-document')
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.7, 0.05),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.2)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.7, 0.05),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=2)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.7, 0.05),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.99)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.7, 0.05),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.9)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.6, 0.2),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.9)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.6, 0.15),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.9)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.6, 0.15),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.15)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.9)
p9
library(ggplot2)
p9 <- ggplot(data.frame(x = c(0, 1)), aes(x = x)) +
stat_function(fun = dnorm, args = list(0.2, 0.1),
colour = "deeppink") +
stat_function(fun = dnorm, args = list(0.6, 0.15),
colour = "dodgerblue3") +
scale_x_continuous(name = "Probability",
breaks = seq(0, 1, 0.2),
limits=c(0, 1)) +
scale_y_continuous(name = "Frequency") +
ggtitle("Normal function curves of probabilities")
# Adding areas under the curve
funcShaded <- function(x) {
y <- dnorm(x, mean = 0.2, sd = 0.1)
y[x < 0.2 | x > (0.2 + 2 * 0.1)] <- NA
return(y)
}
p9 <- p9 + stat_function(fun=funcShaded, geom="area", fill="#84CA72", alpha=0.9)
p9
library(mbmml)
library(bnlearn)
library(gtools)
dag = randDag(8, 2)
graphviz.plot(dag)
dag = randDag(8, 2)
graphviz.plot(dag)
cpts = randCPTs(dag, 2, 1)
n = 100
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
n = 1000
data = rbn(cpts, n)
vars = colnames(data)
nvars = length(vars)
arities = sapply(data, nlevels)
di = varCnt = count_occurance(data, arities)
forward_greedy_fast(data, di, arities, vars, n, "V1", debug = T)
data_num = data.matrix(data)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = T)
forward_greedy(data_num, arities, vars, n, "V4", "nb", debug = T)
forward_greedy(data_num, arities, vars, n, "V4", "random", varCnt = varCnt, prior = "uniform", debug=T)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = F)
forward_greedy(data_num, arities, vars, n, "V4", "nb", debug = F)
forward_greedy(data_num, arities, vars, n, "V4", "random", varCnt = varCnt, prior = "uniform", debug=F)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = F)
forward_greedy(data_num, arities, vars, n, "V4", "nb", debug = F)
forward_greedy(data_num, arities, vars, n, "V4", "random", varCnt = varCnt, prior = "uniform", debug=F)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = T)
dim(data)
table(data$V4,data$V6)
dim(asia)
str(asia)
str(alarm)
table(alarm$ERCA,alarm$PVS)
table(data$V4,data$V6)
?log_factorial
log_gamma(100)
log(factorial(100))
log_gamma(414)-log_gamma(293)-log_gamma(21)
log_gamma(415)-log_gamma(293)-log_gamma(21)
log_gamma(587)-log_gamma(53)-log_gamma(533)
log_gamma(415)-log_gamma(293)-log_gamma(21)+
log_gamma(587)-log_gamma(53)-log_gamma(533)
forward_greedy(data, arities, vars, n, "V4", "cpt", varCnt = di, debug = T)
log_gamma(315)-log_gamma(293)-log_gamma(21)+
log_gamma(587)-log_gamma(53)-log_gamma(533)
log(factorial(587))
log(factorial(315))
log(factorial(21))
log(factorial(53))
log_gamma(53)
log_gamma(315)-log_gamma(293)-log(factanal(21))+
log_gamma(587)-log(factorial(53))-log_gamma(533)
log_gamma(315)-log_gamma(293)-log(factorial(21))+
log_gamma(587)-log(factorial(53))-log_gamma(533)
log_gamma(315)-log_gamma(293)-log_gamma(21)+
log_gamma(587)-log_gamma(53)-log_gamma(533)
forward_greedy(data_num, arities, vars, n, "V4", "nb", debug = T)
forward_greedy(data_num, arities, vars, n, "V4", "random", varCnt = varCnt, prior = "uniform", debug=T)
table(data$V4,data$V6)
log_gamma(315)-log_gamma(293)-log_gamma(21)+
log_gamma(587)-log_gamma(53)-log_gamma(533)
log_gamma(415)-log_gamma(393)-log_gamma(21)+
log_gamma(587)-log_gamma(53)-log_gamma(533)
