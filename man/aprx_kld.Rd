% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/aprx_kld.R
\name{aprx_kld}
\alias{aprx_kld}
\title{Approximation of the KL-Divergence between two distributions.}
\usage{
aprx_kld(data, cptsLearned, logBase = 2, smth = 1e-10)
}
\arguments{
\item{data}{A categorical dataset.}

\item{cptsLearned}{The estimated distribution of a learned BN.}

\item{logBase}{The base of logarithm. Default is 2.}

\item{smth}{A small value to get rid of 0 occurence.}
}
\description{
This function approximates from the learned distribution to the true distribution.
This is not the full kld, it is the last term in Acid and de Campos (2003)'s paper
on page 37. This function only approximates the kld, because the distributions
are estimated by MLE. The reason to not use the true distribution is to get
fast calculation by approximating the joint distributions from data.
}
